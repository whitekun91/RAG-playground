# ğŸ§  RAG Playground

A **FastAPI-based Retrieval-Augmented Generation (RAG)** system with modern UI and comprehensive AI services.  
This project provides a complete RAG solution with STT, TTS, and document processing capabilities using both local and cloud AI models.

---

## ğŸš€ Features

âœ… **Modern Web Interface** - Beautiful, responsive UI with glassmorphism design  
âœ… **FastAPI Backend** - High-performance API with comprehensive endpoints  
âœ… **RAG System** - Document retrieval and question answering  
âœ… **Speech-to-Text (STT)** - Voice input with Whisper support  
âœ… **Text-to-Speech (TTS)** - Audio output with multiple providers  
âœ… **Multi-modal Support** - Text, audio, and image processing  
âœ… **Vector Database** - ChromaDB with embedding models  
âœ… **Document Reranking** - CrossEncoder for improved accuracy  
âœ… **Clean Architecture** - Modular services and core separation  
âœ… **SSL Support** - HTTPS with custom certificates  
âœ… **Virtual Environment** - Python venv for dependency management  

---

## ğŸ—ï¸ System Architecture

```
ğŸ“„ Documents (.pdf, .docx, .pptx, .xlsx)
       â†“ (text/image extraction)
ğŸ§© Chroma VectorDB + CrossEncoder Reranking
       â†“ (similarity search + reranking)
ğŸ§  LLM Engine: Local (vLLM) | Cloud (OpenAI)
       â†“
ğŸ¯ Answer with Evidence
       â†“ (optional)
ğŸ¤ STT (Audio Input) / ğŸ”Š TTS (Audio Output)
```

---

## ğŸ§° Tech Stack

| Component | Description |
|-----------|-------------|
| **Backend** | FastAPI with uvicorn |
| **Frontend** | Modern HTML5 + CSS3 with glassmorphism |
| **Vector DB** | ChromaDB |
| **Embeddings** | Hugging Face (ko-sbert-sts) |
| **Reranker** | bge-reranker-v2-m3 |
| **Local LLM** | vLLM (gemma-3-12b-it) |
| **Cloud LLM** | OpenAI GPT family |
| **STT** | Whisper (local) / OpenAI Whisper API |
| **TTS** | Bark (local) / OpenAI TTS API |
| **Architecture** | Services/Core separation |
| **Virtual Env** | Python venv |

---

## ğŸ“¦ Installation

### 1) Clone Repository
```bash
git clone https://github.com/whitekun91/RAG-playground.git
cd RAG-playground
```

### 2) Create Virtual Environment
```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
```

### 3) Install Dependencies
```bash
pip install -U pip
pip install -r requirements.txt
```

### 4) Environment Configuration
```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your settings
# Required: Set your API keys and model paths
```

---

## âš™ï¸ Environment Configuration (`.env`)

```bash
# VectorDB ê²½ë¡œ
VECTOR_DB_PATH='./documents/vector_db/'

# AI ëª¨ë¸ ê²½ë¡œ
EMBEDDING_MODEL_PATH='./models/embeddings/ko-sbert-sts'
RERANKER_MODEL_PATH='./models/embeddings/bge-reranker-v2-m3'

# í—ˆê¹…í˜ì´ìŠ¤ í† í° (í•„ìš”ì‹œ)
# HF_TOKEN = "your_huggingface_token_here"

# í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§• í•˜ì´í¼íŒŒë¼ë¯¸í„°
CHUNK_SIZE=600
CHUNK_OVERLAP=0

# AI ì„œë¹„ìŠ¤ ì œê³µì (local / openai)
STT_PROVIDER=openai
CHAT_PROVIDER=openai
TTS_PROVIDER=openai

# ë¡œì»¬ LLM ì„¤ì •
LM_MODEL_PATH='./models/LM_Models/gemma-3-12b-it'
VLLM_BASE_URL=http://localhost:8000
VLLM_MODEL=gemma-3-12b-it
VLLM_API_KEY=sk-samples

# OpenAI API ì„¤ì • (í•„ìš”ì‹œ)
# OPENAI_API_KEY='your_openai_api_key_here'
OPENAI_MODEL=gpt-4.1

# LLM í•˜ì´í¼íŒŒë¼ë¯¸í„°
LLM_TEMPERATURE=0.5
LLM_MAX_TOKENS=1024
LLM_TOP_P=0.95
LLM_STOP=<end_of_turn>

# TTS ì„¤ì •
BARK_MODEL_PATH='./models/TTS_Models/bark'
BARK_VOICE_SEMANTIC_PROMPT='./models/TTS_Models/bark/speaker_embeddings/v2/ko_speaker_0_semantic_prompt.npy'
BARK_VOICE_COARSE_PROMPT='./models/TTS_Models/bark/speaker_embeddings/v2/ko_speaker_0_coarse_prompt.npy'
BARK_VOICE_FINE_PROMPT='./models/TTS_Models/bark/speaker_embeddings/v2/ko_speaker_0_fine_prompt.npy'

# STT ëª¨ë¸ ê²½ë¡œ
STT_MODEL_PATH='./models/STT_Models/whisper-large-v3-turbo'

# OpenAI STT/TTS ëª¨ë¸
OPENAI_STT_MODEL=gpt-4o-mini-transcribe
OPENAI_TTS_MODEL=gpt-4o-mini-tts
OPENAI_TTS_VOICE=alloy
OPENAI_TTS_FORMAT=mp3
```

---

## â–¶ï¸ Quick Start

### 1) Start vLLM Server (Optional - for local LLM)
```bash
# GPU ì„¤ì • (ë‹¤ì¤‘ GPU ì‚¬ìš© ì‹œ)
export CUDA_VISIBLE_DEVICES=0,1

# vLLM ì„œë²„ ì‹œì‘
python -m vllm.entrypoints.openai.api_server \
    --model "your-model-path" \
    --served-model-name "gemma-3-12b-it" \
    --dtype bfloat16 \
    --max-model-len 8192 \
    --gpu-memory-utilization 0.65 \
    --tensor-parallel-size 2 \
    --max-num-seqs 16 \
    --swap-space 8 \
    --enable-log-requests \
    --port 8000
```

### 2) Start RAG Playground Server
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” (ì´ë¯¸ í™œì„±í™”ëœ ê²½ìš° ìƒëµ)
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# ì„œë²„ ì‹œì‘
python run_main.py --reload

# SSLë¡œ ì‹¤í–‰ (HTTPS)
python run_main.py --ssl --reload

# í¬íŠ¸ ë³€ê²½
python run_main.py --port 8080 --reload

# í™˜ê²½ í™•ì¸ë§Œ
python run_main.py --check-only
```

### 3) Access Web Interface
- **HTTP**: http://localhost:5001
- **HTTPS**: https://localhost:5001 (SSL ì¸ì¦ì„œ í•„ìš”)

---

## ğŸ’¬ API Endpoints

### ğŸ¯ Main Endpoints

#### `POST /ask-text` - Text Query
```json
{
  "question": "What is the main topic of the document?",
  "return_audio": false
}
```

#### `POST /ask-audio-tts` - Audio Query with TTS
```json
{
  "file": "audio_file.webm",
  "return_audio": true
}
```

### ğŸ“Š System Endpoints

#### `GET /` - Web Interface
Returns the modern HTML interface with glassmorphism design

#### `GET /status` - System Status
```json
{
  "status": "ok",
  "gpu_available": true,
  "device": "NVIDIA GeForce RTX 4090",
  "memory_allocated_MB": 2048,
  "memory_reserved_MB": 4096,
  "uptime_sec": 3600
}
```

#### `GET /metrics` - Performance Metrics
Returns Prometheus-style metrics

#### `GET /download/{filename}` - Download Audio
Download generated TTS audio files

#### `GET /pdf-images/{pdf_name}` - PDF Images
Get extracted images from PDF documents

### ğŸ”§ Example Usage

#### Text Query
```bash
curl -X POST http://localhost:5001/ask-text \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the main topic?",
    "return_audio": false
  }'
```

#### Audio Query with TTS Response
```bash
curl -X POST http://localhost:5001/ask-audio-tts \
  -F "file=@audio.wav" \
  -F "return_audio=true"
```

### ğŸ“ Response Format
```json
{
  "question": "What is the main topic?",
  "rag_answer": "The main topic is...",
  "download_url": "/download/audio_file.wav",
  "image_urls": ["/images/doc1/page1.png"],
  "elapsed_time": "2.5s"
}
```

---

## ğŸ§© Directory Structure

```
RAG-playground/
â”‚
â”œâ”€â”€ main.py                          # FastAPI entry point
â”œâ”€â”€ run_main.py                      # Server startup script
â”œâ”€â”€ setting.py                       # Configuration & environment
â”‚
â”œâ”€â”€ core/                            # Core business logic
â”‚   â”œâ”€â”€ components/                  # Core components
â”‚   â”‚   â”œâ”€â”€ image_loader.py          # Image processing
â”‚   â”‚   â”œâ”€â”€ vector_selector.py       # Vector DB selection
â”‚   â”‚   â””â”€â”€ korean_splitter.py       # Korean text splitting
â”‚   â”œâ”€â”€ interface/                   # Interface layer
â”‚   â”‚   â””â”€â”€ prompts.py               # Prompt templates
â”‚   â”œâ”€â”€ models/                      # Model files & utilities
â”‚   â”‚   â”œâ”€â”€ embeddings/              # Embedding models
â”‚   â”‚   â”œâ”€â”€ stt_models/              # Speech-to-text models
â”‚   â”‚   â”œâ”€â”€ tts_models/              # Text-to-speech models
â”‚   â”‚   â””â”€â”€ model_downloader.py      # Model download utility
â”‚   â”œâ”€â”€ prompts/                     # Prompt templates
â”‚   â”‚   â”œâ”€â”€ db_select_prompt.py      # DB selection prompts
â”‚   â”‚   â”œâ”€â”€ image_detect_prompt.py   # Image detection prompts
â”‚   â”‚   â””â”€â”€ origin_prompt.py         # Base RAG prompts
â”‚   â””â”€â”€ utils/                       # Utility functions
â”‚       â”œâ”€â”€ config.py                # Configuration management
â”‚       â”œâ”€â”€ errors.py                # Error handling
â”‚       â”œâ”€â”€ metrics.py               # Performance metrics
â”‚       â””â”€â”€ observability.py         # Logging & monitoring
â”‚
â”œâ”€â”€ services/                        # Service layer (client-core bridge)
â”‚   â”œâ”€â”€ llm_core.py                  # LLM core functions
â”‚   â”œâ”€â”€ stt_core.py                  # STT core functions
â”‚   â”œâ”€â”€ tts_core.py                  # TTS core functions
â”‚   â”œâ”€â”€ rag/                         # RAG services
â”‚   â”‚   â”œâ”€â”€ chains.py                # Chain services
â”‚   â”‚   â”œâ”€â”€ vector_store.py          # Vector store services
â”‚   â”‚   â”œâ”€â”€ reranker.py              # Document reranking
â”‚   â”‚   â”œâ”€â”€ query_service.py         # Query processing
â”‚   â”‚   â”œâ”€â”€ composer.py              # RAG response composer
â”‚   â”‚   â”œâ”€â”€ image_builder.py         # Image link builder
â”‚   â”‚   â””â”€â”€ db_classifier.py         # Database classification
â”‚   â”œâ”€â”€ pipeline/                    # Pipeline orchestration
â”‚   â”‚   â””â”€â”€ orchestrator.py          # Main pipeline orchestrator
â”‚   â””â”€â”€ providers/                   # Provider managers
â”‚       â”œâ”€â”€ llm_manager.py           # LLM provider management
â”‚       â”œâ”€â”€ stt_manager.py           # STT provider management
â”‚       â””â”€â”€ tts_manager.py           # TTS provider management
â”‚
â”œâ”€â”€ documents/                       # Document storage
â”‚   â”œâ”€â”€ vector_db/                   # Chroma vector database
â”‚   â”œâ”€â”€ extracted_images/            # Extracted images from PDFs
â”‚   â””â”€â”€ raw/                         # Raw document files
â”‚
â”œâ”€â”€ static/                          # Frontend files
â”‚   â”œâ”€â”€ index.html                   # Modern HTML interface
â”‚   â””â”€â”€ style.css                    # Glassmorphism CSS styles
â”‚
â”œâ”€â”€ outputs/                         # Generated outputs
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .env                            # Environment variables (create from .env.example)
â”œâ”€â”€ key.pem                         # SSL private key (for HTTPS)
â”œâ”€â”€ cert.pem                        # SSL certificate (for HTTPS)
â””â”€â”€ README.md                       # This file
```

---

## ğŸ¨ UI Features

- **Modern Design** - Glassmorphism with gradient backgrounds
- **Responsive Layout** - Mobile and desktop optimized
- **Interactive Elements** - Smooth animations and transitions
- **Voice Input** - Real-time speech recognition
- **Audio Output** - Text-to-speech with play controls
- **Image Gallery** - Document image display with modal view
- **Real-time Chat** - Live conversation interface

---

## ğŸ§ª System Requirements

- **Python**: 3.9+
- **OS**: Windows 10+, Ubuntu 20.04+, macOS 10.15+
- **GPU**: NVIDIA GPU with CUDA support (optional)
- **RAM**: 8GB+ recommended
- **Storage**: 10GB+ for models and documents

---

## ğŸ“˜ Roadmap

### âœ… Completed Features
- [x] **Modern UI** - Glassmorphism design with responsive layout
- [x] **STT/TTS Integration** - Whisper STT + Bark/OpenAI TTS
- [x] **Clean Architecture** - Services/Core separation
- [x] **Pipeline Orchestration** - Complex workflow management
- [x] **Multi-modal Support** - Text, audio, and image processing
- [x] **SSL Support** - HTTPS with custom certificates
- [x] **Virtual Environment** - Python venv management

### ğŸš§ In Progress
- [ ] **Performance Optimization** - GPU memory management
- [ ] **Error Handling** - Robust error recovery
- [ ] **Document Upload** - Web interface for document management

### ğŸ”® Future Features
- [ ] **Multi-turn Memory** - Conversation context retention
- [ ] **Smart Document Routing** - Automatic PDF/DOCX/PPTX classification
- [ ] **Evidence Visualization** - Enhanced document evidence display
- [ ] **Real-time Streaming** - Live audio processing
- [ ] **Multi-language Support** - Internationalization
- [ ] **User Authentication** - Login and user management
- [ ] **API Rate Limiting** - Request throttling and quotas

---

## ğŸ§‘â€ğŸ’» Author

**Minwoo Baek**  
Senior AI Engineer | PhD Candidate (Big Data Applications)  
ğŸ’¼ Hanwha Momentum / AI Manufacturing R&D  
ğŸ“§ minwoo713@gmail.com  
ğŸ”— LinkedIn: https://www.linkedin.com/in/bjh713/

---

## ğŸ“œ License

MIT